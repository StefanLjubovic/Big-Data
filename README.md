# Big-Data architectures project- Movie recensions and ratings

## Description

This project uses both batch and real-time processing of movie data. The project can use batch processing to analyze historical movie data and generate insights, while real-time processing can be used to track and analyze current movie trends. The project can use a variety of analytical tools, such as machine learning and statistical analysis, to uncover insights about the movie industry. Some examples of these insights include identifying popular movie genres, predicting box office success, and analyzing the impact of marketing campaigns on movie viewership. Additionally, the project can use visualization tools to present the insights in an easy-to-understand format for stakeholders. Overall, this project can provide valuable insights for movie studios, production companies, and other industry players to make data-driven decisions.

## Data sources

i. IMDB Spoiler Dataset- https://www.kaggle.com/datasets/rmisra/imdb-spoiler-dataset (files: IMDB_movie_details.json(14.18 MB) and IMDB_reviews.json(952.59 MB))
ii. Rotten Tomatoes movies and critic reviews dataset- https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset (files: rotten_tomatoes_critic_reviews.csv(226.05 MB) and rotten_tomatoes_movies.csv(17.12 MB))

## Running application

Before running the movie dataset processing project, it is necessary to first download the movie datasets and place them in the appropriate directory. The datasets should be placed in the Producer/Batch_Producer/Datasets/ directory. Once the datasets are in place, the next step is to run 4 separate docker-compose commands for Spark, Hdfs, Kafka, and the Client. These commands will start the necessary containers for the project to run properly.
After the containers are running, the final step is to execute the start.sh script which is located in the spark-master container. This script runs a series of commands that are required for the project to function properly, such as setting up the HDFS and Kafka clusters, and running the spark code on the movie datasets. Once the script is finished executing, the project will be fully operational and ready to analyze the movie datasets.

## Results
Data visualization is an important aspect of the movie dataset processing project, as it allows stakeholders to easily understand and interpret the insights generated by the analytical tools. The project can use a variety of visualization techniques, such as charts, graphs, and maps, to present the data in a clear and concise manner. These visualizations are generated by metabase.


<img src="https://user-images.githubusercontent.com/73242277/213915836-4da3de7c-bee5-4051-998a-07fdeaa7e458.png" width=400 height=200 />

